{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\anita singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: prophet in c:\\users\\anita singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\n",
      "ERROR: No matching distribution found for pickle\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost prophet pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dtw in c:\\users\\anita singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\anita singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dtw) (1.25.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\anita singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dtw) (1.11.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anita Singh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data and minor EDA\n",
    "\n",
    "We load the data and set the index to be the DateTime column of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "df = pd.read_csv(\"../data/electricityConsumptionAndProductioction.csv\")\n",
    "\n",
    "# set the DateTime as the index\n",
    "df = df.set_index(\"DateTime\")\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "df_elec = pd.read_csv(\"../data/KOL_15mins_final_merged_numeric.csv\")\n",
    "df_temp=df_elec[\"idmeter\"].unique()\n",
    "print(df_temp.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088, 10088]\n"
     ]
    }
   ],
   "source": [
    "df_batch_elec = [df_elec[df_elec[\"idmeter\"]==x].iloc[0:104,1:] for x in df_elec[\"idmeter\"].unique()]\n",
    "df_elec_size_map = [x.size for x in df_batch_elec]\n",
    "print(df_elec_size_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.44100000000001\n"
     ]
    }
   ],
   "source": [
    "from dtw import dtw\n",
    "manhattan_distance = lambda x, y: np.abs(x - y)\n",
    "\n",
    "d, cost_matrix, acc_cost_matrix, path = dtw(df_batch_elec[0].iloc[0,1:], df_batch_elec[1].iloc[0,1:], dist=manhattan_distance)\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "17.44100000000001\n",
      "9.932999999999991\n",
      "12.295999999999998\n",
      "11.588000000000005\n",
      "11.076999999999991\n",
      "15.984999999999994\n",
      "10.604999999999997\n",
      "11.949999999999998\n",
      "15.275999999999996\n",
      "17.44100000000001\n",
      "0.0\n",
      "17.942000000000004\n",
      "3.2919999999999994\n",
      "3.2529999999999952\n",
      "8.047\n",
      "42.20099999999999\n",
      "5.875999999999995\n",
      "9.761999999999997\n",
      "1.6859999999999986\n",
      "9.932999999999991\n",
      "17.942000000000004\n",
      "0.0\n",
      "11.264\n",
      "13.037999999999998\n",
      "8.155999999999999\n",
      "17.028\n",
      "11.176999999999998\n",
      "8.636000000000001\n",
      "15.753\n",
      "12.295999999999998\n",
      "3.2919999999999994\n",
      "11.264\n",
      "0.0\n",
      "3.530999999999996\n",
      "4.8599999999999985\n",
      "34.81399999999998\n",
      "2.8729999999999976\n",
      "7.785\n",
      "1.697999999999998\n",
      "11.588000000000005\n",
      "3.2529999999999952\n",
      "13.037999999999998\n",
      "3.530999999999996\n",
      "0.0\n",
      "5.871999999999997\n",
      "26.03899999999998\n",
      "4.182999999999998\n",
      "8.621999999999998\n",
      "2.760999999999994\n",
      "11.076999999999991\n",
      "8.047\n",
      "8.155999999999999\n",
      "4.8599999999999985\n",
      "5.871999999999997\n",
      "0.0\n",
      "22.798\n",
      "3.413999999999999\n",
      "5.265999999999999\n",
      "5.945999999999998\n",
      "15.984999999999994\n",
      "42.20099999999999\n",
      "17.028\n",
      "34.81399999999998\n",
      "26.03899999999998\n",
      "22.798\n",
      "0.0\n",
      "25.967000000000002\n",
      "18.816\n",
      "39.82500000000001\n",
      "10.604999999999997\n",
      "5.875999999999995\n",
      "11.176999999999998\n",
      "2.8729999999999976\n",
      "4.182999999999998\n",
      "3.413999999999999\n",
      "25.967000000000002\n",
      "0.0\n",
      "6.644999999999998\n",
      "3.717999999999997\n",
      "11.949999999999998\n",
      "9.761999999999997\n",
      "8.636000000000001\n",
      "7.785\n",
      "8.621999999999998\n",
      "5.265999999999999\n",
      "18.816\n",
      "6.644999999999998\n",
      "0.0\n",
      "8.304\n",
      "15.275999999999996\n",
      "1.6859999999999986\n",
      "15.753\n",
      "1.697999999999998\n",
      "2.760999999999994\n",
      "5.945999999999998\n",
      "39.82500000000001\n",
      "3.717999999999997\n",
      "8.304\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "n_size = len(df_elec_size_map)\n",
    "m_size = df_elec_size_map[0]\n",
    "distance_matrix = np.zeros((n_size,n_size))\n",
    "n_size=10\n",
    "for i in range(n_size):\n",
    "    for j in range(n_size):\n",
    "        d, cost_matrix, acc_cost_matrix, path = dtw(df_batch_elec[i].iloc[0,1:], df_batch_elec[j].iloc[0,1:], dist=manhattan_distance)\n",
    "        distance_matrix[i][j] = d\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us print the shape fo our data set and also it's head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"our shape is {df.shape}\")\n",
    "print()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attempt to predict the electricity consumption, so we will drop all the columns except the Consumption (and the DateTime which is now our index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Production\", \"Nuclear\", \"Wind\", \"Hydroelectric\", \"Oil and Gas\", \"Coal\", \"Solar\", \"Biomass\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do a plot in order to the see the data and determine if it has apttern that we can forecast.\n",
    "We will plot out entiere data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Consumption\"]].plot(style=\"-\", figsize=(15, 5), title=\"Electricity Consumption, in MW\")\n",
    "plt.ylabel('MW')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excelent, we can see that our entire dataste (of 4 and a half years) has a seasonality to it.\n",
    "\n",
    "Now let us plot just a week, to see if the seasonality checks up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"2023-01-09 00:00:00\" : \"2023-01-15 23:59:59\"][[\"Consumption\"]].plot(style=\"-\", figsize=(15, 5), title=\"Electricity Consumption, in MW\")\n",
    "plt.ylabel('MW')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we can see that our data has a very nice seasonality to it also at the week level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add features and split the datain train and test sets\n",
    "\n",
    "First let as add some new features that are derived hout the DateTime index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for adding time features by the time index\n",
    "def createTimeFeatures(df):\n",
    "    df[\"hour\"] = df.index.hour\n",
    "    df[\"day_of_week\"] = df.index.day_of_week\n",
    "    df[\"quarter\"] = df.index.quarter\n",
    "    df[\"month\"] = df.index.month\n",
    "    df[\"year\"] = df.index.year\n",
    "    df[\"day_of_year\"] = df.index.dayofyear\n",
    "\n",
    "\n",
    "# apply the method to the existing dataframe\n",
    "createTimeFeatures(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us split the data, we will use the last year as our dataset.\n",
    "\n",
    "Do also a simple plot to see as a graph what is the percentage of the train versus datasets. A red vetical line will represent the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutOffDate = df.index[-365 * 24]\n",
    "print(f\"cutOffDate {cutOffDate}\")\n",
    "\n",
    "train = df.loc[df.index <= cutOffDate]\n",
    "test = df.loc[df.index > cutOffDate]\n",
    "\n",
    "print(f\"train size: {len(train)} and test {len(test)}\")\n",
    "\n",
    "df[[\"Consumption\"]].plot(style=\"-\", figsize=(15, 5), title=\"Electricity Consumption, in MW\")\n",
    "plt.ylabel('MW')\n",
    "plt.axvline(x=cutOffDate, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, now we have augmented our dataframe with some new features and we have split the dataframe in train and test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create simple method for calculating the error\n",
    "\n",
    "We want to create a simple method that will show the error betwne the actual value and predicted value as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanAbsolutErrorAaPercentage(real, predicted):\n",
    "    real = np.array(real)\n",
    "    predicted = np.array(predicted)\n",
    "\n",
    "    return np.mean(np.abs((real - predicted) / real)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting using Regression\n",
    "\n",
    "Here we will prepare our data in train and test Xs and ys and use a XGB regressor to predict the target feature or our training part of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define our features and our target as separate arrays\n",
    "FEATURES = [\"hour\", \"day_of_week\", \"quarter\", \"month\", \"year\", \"day_of_year\"]\n",
    "TARGET = \"Consumption\"\n",
    "\n",
    "X_train = train[FEATURES]\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_test = test[FEATURES]\n",
    "y_test = test[TARGET]\n",
    "\n",
    "# define and XGB regressor, fit it on our train data and use it to predict our test data\n",
    "regressor = xgb.XGBRegressor(n_estimators=1000, early_stoppin_rounds=50, learning_rate=0.01)\n",
    "\n",
    "regressor.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=100)\n",
    "regressorOutput = regressor.predict(X_test)\n",
    "\n",
    "prediction = pd.DataFrame(data=regressorOutput, index=X_test.index, columns=[\"prediction\"])\n",
    "\n",
    "df = df.merge(prediction, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "# our predictions are at the end of the dataframe, so we should print that\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(regressor, open('elecModel.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the error withe method that we defined before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the part of the data frame that is our test part\n",
    "testDf = df.loc[df.index > cutOffDate]\n",
    "\n",
    "yReal = testDf[\"Consumption\"]\n",
    "yPredicted = testDf[\"prediction\"]\n",
    "\n",
    "print(f\"percentage error: {meanAbsolutErrorAaPercentage(yReal, yPredicted):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so the percentage error between the predicted and actual value is a little over 10%, **10.1803** precisily.\n",
    "\n",
    "Now let's plot the prediction over the actual data, first for all the dataset and after for just a week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[[TARGET]].plot(figsize=(15,5))\n",
    "df[\"prediction\"].plot(ax=ax, style=\".\")\n",
    "ax.legend([\"True Data\", \"Prediction\"])\n",
    "ax.set_title(\"Data and prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[\"2023-01-09 00:00:00\" : \"2023-01-15 23:59:59\"][[TARGET]].plot(figsize=(15,5))\n",
    "df[\"2023-01-09 00:00:00\" : \"2023-01-15 23:59:59\"][\"prediction\"].plot(ax=ax, style=\".\")\n",
    "ax.legend([\"True Data\", \"Prediction\"])\n",
    "ax.set_title(\"Data and prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we plot the data for the entiere time range and also for just a week. The difference of about 10% is clearly visible but the regression model did pick up the pattern very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting using Prophet\n",
    "\n",
    "Prophet is a time series prediction library developed by Facebook/Meta. It is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality.\n",
    "\n",
    "Prophet needs to be imported, as we did at the start of this notebook.\n",
    "\n",
    "Prophets wan to have the date time column names as **ds**, and the target as **y**. So we will reset our index and rename our columns as needed.\n",
    "\n",
    "We will do this for both our train and test dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophetTrain = train.reset_index()\n",
    "prophetTrain.drop(FEATURES, axis=1, inplace=True)\n",
    "prophetTrain.rename(columns={\"DateTime\": \"ds\", \"Consumption\": \"y\"}, inplace=True)\n",
    "\n",
    "prophetTrain.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophetTest = test.reset_index()\n",
    "prophetTest.drop(FEATURES, axis=1, inplace=True)\n",
    "prophetTest.rename(columns={\"DateTime\": \"ds\", \"Consumption\": \"y\"}, inplace=True)\n",
    "\n",
    "prophetTest.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's create the Prophet object, fit it on the train data and use the test data for predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "prophetModel = Prophet()\n",
    "prophetModel.fit(prophetTrain)\n",
    "\n",
    "prophetPrediction = prophetModel.predict(prophetTest)\n",
    "\n",
    "yRealProphet = test[\"Consumption\"]\n",
    "yPredictedProphet = prophetPrediction[\"yhat\"]\n",
    "\n",
    "print(f\"prophet percentage error: {meanAbsolutErrorAaPercentage(yRealProphet, yPredictedProphet):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Prophet prediction is out of the box at an about 5% error, **5.5591** precisily.\n",
    "\n",
    "Now let's also plot the predinction for the Prophet prediction. For the entiere data set and then for just a week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to be optimaly plot the data we set it's ds (our initial DateTime) as the index\n",
    "prophetPrediction = prophetPrediction.set_index(\"ds\")\n",
    "\n",
    "ax = df[[TARGET]].plot(figsize=(15,5))\n",
    "prophetPrediction[\"yhat\"].plot(ax=ax, style=\".\", color=\"g\")\n",
    "ax.legend([\"True Data\", \"Prediction\"])\n",
    "ax.set_title(\"Data and prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[\"2023-01-09 00:00:00\" : \"2023-01-15 23:59:59\"][[TARGET]].plot(figsize=(15,5))\n",
    "prophetPrediction[\"2023-01-09 00:00:00\" : \"2023-01-15 23:59:59\"][\"yhat\"].plot(ax=ax, style=\".\", color=\"g\")\n",
    "ax.legend([\"True Data\", \"Prediction\"])\n",
    "ax.set_title(\"Data and prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the Prophet prediction looks pretty good, after plotting it's easy to see that the trend is followed pretty well and we get a smaller error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
